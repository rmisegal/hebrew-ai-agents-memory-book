\hebrewsection{אתיקה, פרטיות ואבטחה בסוכני AI: סיכונים ופתרונות}

\hebrewsubsection{היבטי אתיקה ופרטיות}

הכנסת סוכנים אוטונומיים הפועלים על מידע אישי מעוררת שאלות אתיות מהותיות. ראשית, סוגיית \textbf{הפרטיות}: בדוגמתנו, סוכן ה\en{-Gmail} ניגש לתוכן תיבת הדוא"ל של המשתמש. חובה לוודא שהמשתמש העניק הסכמה מפורשת לגישה כזו, ולהגדיר גבולות ברורים למידע שהסוכן רשאי לחלץ. עקרון \textbf{הצמצום} הוא מפתח – על הסוכן לאסוף רק את הנתונים ההכרחיים למשימה, ולא יותר. בנוסף, יש לנקוט צעדים למניעת זליגת מידע רגיש: במערכת שלנו, התקשורת בין הסוכן למודל (\en{Claude}) צריכה להיות מוצפנת ומאובטחת. אם פלטפורמת ה\en{-AI} מריצה את המודל בענן, יש לשקול מי נושא באחריות לשמירת המידע המועבר (למשל, עמידה בדרישות תקנות \textbf{GDPR} באיחוד האירופי).

מן ההיבט האתי, עלינו לשמור על \textbf{שקיפות}: המשתמש צריך לדעת כאשר תשובה שסופקה לו מבוססת על פעולת סוכן אוטונומי ובאילו מקורות מידע הסוכן השתמש. שקיפות זו חיונית לבניית אמון, במיוחד כאשר החלטות הנגזרות מפלט הסוכנים עשויות להשפיע על אנשים. למשל, אם סוכן \en{AI} משמש למיון קורות חיים של מועמדים, מן הדין שהמועמדים יידעו על כך, ויש לוודא שהסוכן תוכנן ללא הטיות מפלות. במערכות רב-סוכנים, עולה גם שאלת ההטיה המצטברת: אם כל סוכן לוקה בהטיה קלה, שילוב התוצאות עשוי להגביר את ההטיה. אחת הדרכים להתמודד היא שמירה על ביקורת אנושית בתהליכים קריטיים, או הטמעת כללי אתיקה מפורשים (כגון מסננים למניעת אפליה) בלוגיקת הפעולה של הסוכנים.

\hebrewsubsection{איומי אבטחה ודרכי התגוננות}

ארכיטקטורת רב-סוכנים מציגה שטח תקיפה רחב הדורש התייחסות. ננתח כמה וקטורי איום מרכזיים:
\begin{itemize}
\item \textbf{ניצול פרצת תוכנה בסוכן:} סוכן ה\en{-MCP} שלנו הוא תוכנה שרצה בסביבה מקומית עם גישה למידע רגיש (דוא"ל המשתמש). תוקף עשוי לנסות לנצל חולשת אבטחה בקוד הסוכן או בספריות שבהן הוא משתמש כדי להשתלט עליו. הגנה: הפעלת הסוכן בסביבת ריצה מבודדת (כגון מכולה ייעודית עם הרשאות מינימליות), ושמירה על עדכניות ספריות ועדכוני אבטחה.
\item \textbf{הונאת המתווך (\en{Prompt Injection}):} מכיוון ש\en{-Claude} מתווך בין המשתמש לסוכן, תוקף יכול לנסות לספק קלט זדוני שישכנע את המודל לבצע פעולות לא רצויות או לחשוף מידע. למשל, פקודה הבנויה באופן מתוחכם יכולה לגרום למודל לשלוח לסוכן פרמטרים לא צפויים. הגנה: החלת סינון ובקרה על קלט המשתמש (למשל, זיהוי ניסיון להזריק פקודות) והגבלת הפקודות שהמודל רשאי להעביר לסוכן בהתאם למדיניות מערכת מוגדרת.
\item \textbf{הסלמת הרשאות בין-סוכנים:} במערכת עם סוכנים מרובים, ייתכן שסוכן אחד ינסה (שלא במתכוון או בזדון) לגשת למשאבים של סוכן אחר. הגנה: עקרון ההרשאה המזערית – יש להקצות לכל סוכן רק את המשאבים וההרשאות הנחוצים לו בלבד. למשל, סוכן \en{Gmail} אינו זקוק לגישה לרשת או לקבצי מערכת שאינם קשורים למשימתו.
\item \textbf{שימוש זדוני בסוכנים מצד גורם פנימי:} משתמש-על או מפעיל זדוני בעל גישה למערכת יכול לנסות לרתום סוכנים לביצוע פעולות לא מורשות (כגון חילוץ מידע והדלפתו). הגנה: רישום וביקורת – יש לתעד פעולות של הסוכנים (\en{log}) במיוחד בעת גישה למידע רגיש, ולהגביל יכולת הפעלה ישירה של סוכנים רק למשתמשים מורשים.
\end{itemize}

נושא נוסף הוא \textbf{שרידות המערכת} בפני תקלות. ניקח הסתברות כשל $\epsilon$ לכל סוכן בפעולה מסוימת. אם משימה מצריכה מעבר סדרתי דרך $n$ סוכנים, ההסתברות שכל השרשרת תצליח היא $(1-\epsilon)^n$. עבור $\epsilon$ קטן, אפשר לקרב זאת ל\en{-}$1 - n\epsilon$ (בקירוב לינארי). כלומר, ככל שהמשימה נשענת על יותר סוכנים ברצף, עולה הסיכון לכשל באחד מהם. לשם צמצום סיכון זה ניתן ליישם יתירות – למשל, להפעיל מנגנון שחוזר על קריאת סוכן שלא הגיב, או להחזיק סוכן גיבוי חלופי. בנוסף, רצוי שהמודל המרכזי יהיה מודע לכשלים ויוכל לנסות נתיב פעולה חלופי או לדווח למשתמש על תקלה חלקית במקום כישלון כולל.

מעבר להגנות הטכניות, יש חשיבות גם לתחושת האמון של המשתמשים. מומלץ לפרסם תיעוד מדיניות אבטחה ופרטיות, לעמוד בתקנים (כגון תקן \en{ISO 27001} לניהול אבטחת מידע), ואף לבצע ביקורות חיצוניות על מערך הסוכנים. צעדים אלו משמשים כבקרת איכות ומשפרים את אמון הציבור במערכת. בסיכומו של דבר, אימוץ סוכני \en{AI} מצריך תשומת לב קפדנית לסיכוני אבטחה ופרטיות, כדי שהמערכות יניבו את התועלת הרבה הגלומה בהן בלי לפגוע במשתמשים או במידע שלהם.
